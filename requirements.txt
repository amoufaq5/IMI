# IMI - Intelligent Medical Intelligence
# Medical LLM Fine-tuning + Reinforcement Learning Pipeline
# Optimized for multi-GPU training (H100/A100)

# ============================================================
# CORE ML/DL - PyTorch & Transformers
# ============================================================
torch>=2.2.0
transformers>=4.40.0
accelerate>=0.28.0
safetensors>=0.4.2
einops>=0.7.0

# ============================================================
# FINE-TUNING (SFT + LoRA/QLoRA)
# ============================================================
peft>=0.10.0
trl>=0.8.0                    # SFT, DPO, PPO, ORPO trainers
bitsandbytes>=0.43.0          # 4-bit/8-bit quantization

# ============================================================
# DISTRIBUTED TRAINING
# ============================================================
deepspeed>=0.14.0
ninja>=1.11.1                 # JIT compilation for custom CUDA

# ============================================================
# FLASH ATTENTION (long context)
# ============================================================
flash-attn>=2.5.0             # Install separately: pip install flash-attn --no-build-isolation

# ============================================================
# DATASETS & TOKENIZATION
# ============================================================
datasets>=2.18.0
tokenizers>=0.15.2
sentencepiece>=0.2.0

# ============================================================
# REINFORCEMENT LEARNING (RLHF/DPO/PPO)
# ============================================================
# trl already includes DPO, PPO, ORPO trainers
# Additional RL utilities:
gymnasium>=0.29.0             # RL environments (optional)

# ============================================================
# DATA PROCESSING
# ============================================================
numpy>=1.26.0,<2.0            # Must be <2.0 for PyTorch compatibility
pandas>=2.2.0
scipy>=1.12.0
scikit-learn>=1.4.0
pyarrow>=15.0.0

# ============================================================
# DATA INGESTION (Scrapers)
# ============================================================
httpx>=0.27.0                 # Async HTTP client
aiohttp>=3.9.0                # Async HTTP
requests>=2.31.0              # Sync HTTP
beautifulsoup4>=4.12.0        # HTML parsing
lxml>=5.1.0                   # XML parsing
kaggle>=1.6.0                 # Kaggle datasets API

# ============================================================
# EXPERIMENT TRACKING & LOGGING
# ============================================================
wandb>=0.16.0                 # Weights & Biases
tensorboard>=2.16.0
rich>=13.7.0                  # Beautiful terminal output
tqdm>=4.66.0

# ============================================================
# EVALUATION & METRICS
# ============================================================
evaluate>=0.4.0               # HuggingFace evaluate
rouge-score>=0.1.2
nltk>=3.8.0
bert-score>=0.3.13

# ============================================================
# INFERENCE & SERVING (for apps)
# ============================================================
vllm>=0.4.0                   # Fast LLM inference
gradio>=4.20.0                # Quick UI for apps
fastapi>=0.110.0              # API serving
uvicorn>=0.29.0

# ============================================================
# UTILITIES
# ============================================================
python-dotenv>=1.0.0
pyyaml>=6.0.1
orjson>=3.9.0
tenacity>=8.2.0               # Retry logic for API calls
typer>=0.9.0                  # CLI framework
